<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>bokeh effect generator</title>
    <link href="output.css" rel="stylesheet">
    <style>
        /* Essential styles for click indicator and loading spinner */
        .click-indicator {
            position: absolute;
            width: 6px;
            height: 6px;
            background-color: red;
            border-radius: 50%;
            transform: translate(-50%, -50%);
            pointer-events: none;
            opacity: 0.7;
        }

        .loading-overlay {
            display: none;
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: rgba(255, 255, 255, 0.9);
            justify-content: center;
            align-items: center;
            z-index: 10;
        }

        @keyframes spin {
            0% {
                transform: rotate(0deg);
            }

            100% {
                transform: rotate(360deg);
            }
        }

        .spinner {
            width: 40px;
            height: 40px;
            border: 4px solid #f3f3f3;
            border-top: 4px solid black;
            border-radius: 50%;
            animation: spin 1s linear infinite;
        }
    </style>
</head>

<body class="bg-zinc-100 min-h-screen p-4">
    <div class="bg-white max-w-2xl mx-auto p-6">
        <h1 class="mt-0">Bokeh Magic</h1>

        <p>
            Upload a photo, then click to set the focus. Use the sliders to adjust the blur strength.
        </p>

        <input class="mt-2" type="file" id="imageUpload" accept="image/*">

        <div class="mt-6">
            <div class="relative">
                <div class="relative">
                    <canvas id="originalCanvas" class="w-full"></canvas>
                    <div id="clickIndicator" class="click-indicator" style="display: none;"></div>
                    <div id="loadingOverlay" class="loading-overlay">
                        <div class="spinner"></div>
                    </div>
                </div>

                <div id="statusText" class="mt-2 h-6 block text-zinc-500">
                    Loading depth model, please wait...
                </div>

                <div class="mt-6 space-y-4">
                    <div class="flex items-center gap-4">
                        <label for="blurStrength" class="w-24">Blur Strength</label>
                        <!-- TODO: max 6 -->
                        <input type="range" id="blurStrength" min="1" max="7" step="0.1" value="4" class="flex-1"
                            disabled>
                        <input type="number" id="blurStrengthValue" min="1" max="7" step="0.1" value="4" class="w-16"
                            disabled>
                    </div>
                    <div class="flex items-center gap-4">
                        <label for="depthOfField" class="w-24">Depth of Field</label>
                        <input type="range" id="depthOfField" min="0.01" max="0.5" step="0.01" value="0.1"
                            class="flex-1" disabled>
                        <input type="number" id="depthOfFieldValue" min="0.01" max="0.5" step="0.01" value="0.1"
                            class="w-16" disabled>
                    </div>
                    <div class="flex items-center gap-4">
                        <label for="bokehShape" class="w-24">Bokeh Shape</label>
                        <select id="bokehShape" class="rounded border border-gray-300 px-2 py-1" disabled>
                            <option value="circle">Circle</option>
                            <option value="square">Square</option>
                            <option value="hexagon">Hexagon</option>
                        </select>
                    </div>
                    <div class="flex items-center gap-4">
                        <label for="backgroundOnly" class="w-72">Only blur background (reduces artifacts)</label>
                        <input type="checkbox" id="backgroundOnly" class="h-4 w-4" checked disabled>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <script type="module">
        import { pipeline, env } from 'https://cdn.jsdelivr.net/npm/@huggingface/transformers@3.4.2/dist/transformers.min.js';

        let originalImage = null;
        let depthData = null;

        function setControlsEnabled(enabled) {
            blurStrength.disabled = !enabled;
            blurStrengthValue.disabled = !enabled;
            depthOfField.disabled = !enabled;
            depthOfFieldValue.disabled = !enabled;
            bokehShape.disabled = !enabled;
            backgroundOnly.disabled = !enabled;
        }

        function resetUIState() {
            setControlsEnabled(false);
            clickIndicator.style.display = 'none';
            depthData = null;
            originalPixels = null;
        }

        // Start loading the depth model
        let depthEstimator = null;
        let modelLoading = true;
        pipeline('depth-estimation', 'onnx-community/depth-anything-v2-base', {
            device: 'webgpu',
        }).then(model => {
            depthEstimator = model;
            modelLoading = false;
            updateStatus('Click anywhere on the image to set focus point.');
            if (originalImage) {
                // If an image was already loaded, enable click handling
                originalCanvas.style.cursor = 'crosshair';
            }
        }).catch(error => {
            console.error('Error loading model:', error);
            updateStatus('Error loading model. Please refresh the page.');
        });

        const imageUpload = document.getElementById('imageUpload');
        const originalCanvas = document.getElementById('originalCanvas');
        const loadingOverlay = document.getElementById('loadingOverlay');
        const blurStrength = document.getElementById('blurStrength');
        const blurStrengthValue = document.getElementById('blurStrengthValue');
        const depthOfField = document.getElementById('depthOfField');
        const depthOfFieldValue = document.getElementById('depthOfFieldValue');
        const bokehShape = document.getElementById('bokehShape');
        const backgroundOnly = document.getElementById('backgroundOnly');
        const clickIndicator = document.getElementById('clickIndicator');

        let device = null;
        let cocPipeline = null;
        let toLinearPipeline = null;
        let blurHPipeline = null;
        let blurVPipeline = null;
        let toSrgbPipeline = null;
        let toLinearBindGroup = null;
        let blurHBindGroup = null;
        let blurVBindGroup = null;
        let toSrgbBindGroup = null;
        let originalPixels = null;

        // Sync number inputs with range inputs
        blurStrength.addEventListener('input', (e) => {
            blurStrengthValue.value = e.target.value;
        });
        blurStrengthValue.addEventListener('input', (e) => {
            blurStrength.value = e.target.value;
        });
        depthOfField.addEventListener('input', (e) => {
            depthOfFieldValue.value = e.target.value;
        });
        depthOfFieldValue.addEventListener('input', (e) => {
            depthOfField.value = e.target.value;
        });

        async function initWebGPU() {
            if (!navigator.gpu) {
                throw new Error("WebGPU not supported");
            }

            const adapter = await navigator.gpu.requestAdapter();
            if (!adapter) {
                throw new Error("No GPU adapter found");
            }

            device = await adapter.requestDevice({
                requiredLimits: {
                    maxStorageBufferBindingSize: adapter.limits.maxStorageBufferBindingSize,
                    maxBufferSize: adapter.limits.maxBufferSize
                }
            });

            // Load and compile all shaders
            const [cocCode, toLinearCode, blurHLinearCode, blurVLinearCode, toSrgbCode] = await Promise.all([
                fetch('coc.wgsl').then(r => r.text()),
                fetch('convert_to_linear.wgsl').then(r => r.text()),
                fetch('blur_h_linear.wgsl').then(r => r.text()),
                fetch('blur_v_linear.wgsl').then(r => r.text()),
                fetch('convert_to_srgb.wgsl').then(r => r.text())
            ]);

            const cocShaderModule = device.createShaderModule({
                code: cocCode
            });

            const toLinearShaderModule = device.createShaderModule({
                code: toLinearCode
            });

            const blurHShaderModule = device.createShaderModule({
                code: blurHLinearCode
            });

            const blurVShaderModule = device.createShaderModule({
                code: blurVLinearCode
            });

            const toSrgbShaderModule = device.createShaderModule({
                code: toSrgbCode
            });

            // Create pipelines for all passes
            cocPipeline = device.createComputePipeline({
                layout: 'auto',
                compute: {
                    module: cocShaderModule,
                    entryPoint: 'main'
                }
            });

            toLinearPipeline = device.createComputePipeline({
                layout: 'auto',
                compute: {
                    module: toLinearShaderModule,
                    entryPoint: 'main'
                }
            });

            blurHPipeline = device.createComputePipeline({
                layout: 'auto',
                compute: {
                    module: blurHShaderModule,
                    entryPoint: 'main'
                }
            });

            blurVPipeline = device.createComputePipeline({
                layout: 'auto',
                compute: {
                    module: blurVShaderModule,
                    entryPoint: 'main'
                }
            });

            toSrgbPipeline = device.createComputePipeline({
                layout: 'auto',
                compute: {
                    module: toSrgbShaderModule,
                    entryPoint: 'main'
                }
            });

            console.log("WebGPU initialized");
        }

        async function applyBokeh(canvas, focusDepth) {
            if (!depthData || !originalPixels) {
                console.error("No depth data or original image available");
                return;
            }

            const ctx = canvas.getContext('2d');

            // Create input buffer and copy original pixels to it
            const inputPackedBuffer = device.createBuffer({
                size: originalPixels.byteLength,
                usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST,
            });
            device.queue.writeBuffer(inputPackedBuffer, 0, originalPixels);

            // Create depth map buffer
            const depthValues = new Float32Array(depthData.values);
            const depthBuffer = device.createBuffer({
                size: depthValues.byteLength,
                usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST,
            });
            device.queue.writeBuffer(depthBuffer, 0, depthValues);

            // Create CoC buffer
            const cocBuffer = device.createBuffer({
                size: depthValues.byteLength * 4, // float32 for each pixel
                usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST,
            });

            // Create buffers for linear space processing
            const linearBuffer = device.createBuffer({
                size: originalPixels.byteLength * 4, // vec4<f32> uses 16 bytes per pixel (4x more than packed u32)
                usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST | GPUBufferUsage.COPY_SRC,
            });

            const intermediateLinearBuffer = device.createBuffer({
                size: originalPixels.byteLength * 4, // vec4<f32> uses 16 bytes per pixel
                usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST | GPUBufferUsage.COPY_SRC,
            });

            const outputLinearBuffer = device.createBuffer({
                size: originalPixels.byteLength * 4, // vec4<f32> uses 16 bytes per pixel
                usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST | GPUBufferUsage.COPY_SRC,
            });

            // Create output packed buffer
            const outputPackedBuffer = device.createBuffer({
                size: originalPixels.byteLength,
                usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC,
            });

            // Create params buffer with width, height and shape
            const shaderParamsBuffer = device.createBuffer({
                size: 16, // 3 u32s (width, height, shape) + padding to 16 bytes
                usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,
            });
            // Convert shape value to uint: 0 = circle, 1 = square, 2 = hexagon
            let shapeValue = 0;
            if (bokehShape.value === 'square') shapeValue = 1;
            else if (bokehShape.value === 'hexagon') shapeValue = 2;
            const shaderParamsArray = new Uint32Array([canvas.width, canvas.height, shapeValue, 0]); // last 0 is padding
            device.queue.writeBuffer(shaderParamsBuffer, 0, shaderParamsArray);

            // Create conversion params buffer (just width and height)
            const convertParamsBuffer = device.createBuffer({
                size: 16, // 2 u32s (width, height) + padding to 16 bytes
                usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,
            });
            const convertParamsArray = new Uint32Array([canvas.width, canvas.height, 0, 0]); // extra 0s for padding
            device.queue.writeBuffer(convertParamsBuffer, 0, convertParamsArray);

            // Create CoC params uniform buffer
            const cocParamsBuffer = device.createBuffer({
                size: 16, // 4 floats: focus_depth, max_coc, depth_of_field, background_only
                usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,
            });
            const maxCoc = 0.001 * 0.5 * (canvas.width + canvas.height) * Math.pow(2, parseFloat(blurStrength.value));
            const cocParamsArray = new Float32Array([
                focusDepth,
                maxCoc,
                parseFloat(depthOfField.value),
                backgroundOnly.checked ? 1 : 0
            ]);
            device.queue.writeBuffer(cocParamsBuffer, 0, cocParamsArray);

            // Create staging buffer for reading back the result
            const stagingBuffer = device.createBuffer({
                size: originalPixels.byteLength,
                usage: GPUBufferUsage.MAP_READ | GPUBufferUsage.COPY_DST,
            });

            // Create bind groups for all passes
            const cocBindGroup = device.createBindGroup({
                layout: cocPipeline.getBindGroupLayout(0),
                entries: [
                    { binding: 0, resource: { buffer: depthBuffer } },
                    { binding: 1, resource: { buffer: cocBuffer } },
                    { binding: 2, resource: { buffer: shaderParamsBuffer } },
                    { binding: 3, resource: { buffer: cocParamsBuffer } },
                ],
            });

            // Bind group for converting to linear space
            const toLinearBindGroup = device.createBindGroup({
                layout: toLinearPipeline.getBindGroupLayout(0),
                entries: [
                    { binding: 0, resource: { buffer: inputPackedBuffer } },
                    { binding: 1, resource: { buffer: linearBuffer } },
                    { binding: 2, resource: { buffer: convertParamsBuffer } },
                ],
            });

            // Bind group for horizontal blur in linear space
            const blurHBindGroup = device.createBindGroup({
                layout: blurHPipeline.getBindGroupLayout(0),
                entries: [
                    { binding: 0, resource: { buffer: linearBuffer } },
                    { binding: 1, resource: { buffer: intermediateLinearBuffer } },
                    { binding: 2, resource: { buffer: shaderParamsBuffer } },
                    { binding: 3, resource: { buffer: cocBuffer } },
                ],
            });

            // Bind group for vertical blur in linear space
            const blurVBindGroup = device.createBindGroup({
                layout: blurVPipeline.getBindGroupLayout(0),
                entries: [
                    { binding: 0, resource: { buffer: intermediateLinearBuffer } },
                    { binding: 1, resource: { buffer: outputLinearBuffer } },
                    { binding: 2, resource: { buffer: shaderParamsBuffer } },
                    { binding: 3, resource: { buffer: cocBuffer } },
                ],
            });
            
            // Bind group for converting back to sRGB
            const toSrgbBindGroup = device.createBindGroup({
                layout: toSrgbPipeline.getBindGroupLayout(0),
                entries: [
                    { binding: 0, resource: { buffer: outputLinearBuffer } },
                    { binding: 1, resource: { buffer: outputPackedBuffer } },
                    { binding: 2, resource: { buffer: convertParamsBuffer } },
                ],
            });

            // Create and submit command buffer for all passes
            const commandEncoder = device.createCommandEncoder();

            // First pass: compute CoC values
            const cocPass = commandEncoder.beginComputePass();
            cocPass.setPipeline(cocPipeline);
            cocPass.setBindGroup(0, cocBindGroup);
            cocPass.dispatchWorkgroups(
                Math.ceil(canvas.width / 8),
                Math.ceil(canvas.height / 8)
            );
            cocPass.end();
            
            // Convert to linear space
            const toLinearPass = commandEncoder.beginComputePass();
            toLinearPass.setPipeline(toLinearPipeline);
            toLinearPass.setBindGroup(0, toLinearBindGroup);
            toLinearPass.dispatchWorkgroups(
                Math.ceil(canvas.width / 8),
                Math.ceil(canvas.height / 8)
            );
            toLinearPass.end();

            // Horizontal blur pass (in linear space)
            const blurHPass = commandEncoder.beginComputePass();
            blurHPass.setPipeline(blurHPipeline);
            blurHPass.setBindGroup(0, blurHBindGroup);
            blurHPass.dispatchWorkgroups(
                Math.ceil(canvas.width / 8),
                Math.ceil(canvas.height / 8)
            );
            blurHPass.end();

            // Vertical blur pass (in linear space)
            const blurVPass = commandEncoder.beginComputePass();
            blurVPass.setPipeline(blurVPipeline);
            blurVPass.setBindGroup(0, blurVBindGroup);
            blurVPass.dispatchWorkgroups(
                Math.ceil(canvas.width / 8),
                Math.ceil(canvas.height / 8)
            );
            blurVPass.end();
            
            // Convert back to sRGB space
            const toSrgbPass = commandEncoder.beginComputePass();
            toSrgbPass.setPipeline(toSrgbPipeline);
            toSrgbPass.setBindGroup(0, toSrgbBindGroup);
            toSrgbPass.dispatchWorkgroups(
                Math.ceil(canvas.width / 8),
                Math.ceil(canvas.height / 8)
            );
            toSrgbPass.end();

            // Copy output to staging buffer
            commandEncoder.copyBufferToBuffer(
                outputPackedBuffer, 0,
                stagingBuffer, 0,
                originalPixels.byteLength
            );

            device.queue.submit([commandEncoder.finish()]);

            // Read back the result
            await stagingBuffer.mapAsync(GPUMapMode.READ);
            const blurredPixels = new Uint8Array(stagingBuffer.getMappedRange());
            const blurredImageData = new ImageData(
                new Uint8ClampedArray(blurredPixels),
                canvas.width,
                canvas.height
            );
            ctx.putImageData(blurredImageData, 0, 0);
            stagingBuffer.unmap();

            console.log("Bokeh effect applied with focus depth:", focusDepth, "max_coc:", maxCoc, "depth_of_field:", depthOfField.value);
        }

        function drawImageToCanvas(canvas, img) {
            const ctx = canvas.getContext('2d');
            canvas.width = img.width;
            canvas.height = img.height;
            ctx.drawImage(img, 0, 0);

            // Store original pixels when first drawing the image
            const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
            originalPixels = new Uint32Array(imageData.data.buffer);

            return ctx;
        }

        const statusText = document.getElementById('statusText');
        const controls = document.querySelectorAll('input[type="range"], input[type="number"], input[type="checkbox"], select');

        function updateStatus(text, visible = true) {
            statusText.textContent = text;
            statusText.style.visibility = visible ? 'visible' : 'hidden';
        }

        // Add event listeners for the sliders to reapply effect when changed
        let lastClickedPos = null;

        async function updateEffect() {
            if (!lastClickedPos) return;

            try {
                updateStatus('processing...');
                const { x, y } = lastClickedPos;
                const index = y * depthData.width + x;
                const depth = depthData.values[index];

                await applyBokeh(originalCanvas, depth);
                updateStatus('processing...', false);
            } catch (error) {
                console.error('Error applying bokeh:', error);
                updateStatus('error applying effect', true);
            } finally {
            }
        }

        blurStrength.addEventListener('input', updateEffect);
        depthOfField.addEventListener('input', updateEffect);
        bokehShape.addEventListener('change', updateEffect);
        backgroundOnly.addEventListener('change', updateEffect);

        originalCanvas.addEventListener('click', async (event) => {
            if (!depthData) return;

            const rect = originalCanvas.getBoundingClientRect();
            const scaleX = originalCanvas.width / rect.width;
            const scaleY = originalCanvas.height / rect.height;

            const x = Math.floor((event.clientX - rect.left) * scaleX);
            const y = Math.floor((event.clientY - rect.top) * scaleY);

            // Update click indicator position
            clickIndicator.style.display = 'block';
            clickIndicator.style.left = (event.clientX - rect.left) + 'px';
            clickIndicator.style.top = (event.clientY - rect.top) + 'px';

            lastClickedPos = { x, y };
            const index = y * depthData.width + x;
            const depth = depthData.values[index];

            console.log(`Depth at (${x}, ${y}): ${depth.toFixed(3)}`);
            updateStatus('processing...');
            await applyBokeh(originalCanvas, depth);
            updateStatus('processing...', false);
            setControlsEnabled(true);
        });

        // Initialize WebGPU when the page loads
        initWebGPU().catch(console.error);

        imageUpload.addEventListener('change', async (event) => {
            const file = event.target.files[0];
            if (!file) return;

            resetUIState();
            loadingOverlay.style.display = 'flex';
            updateStatus('Loading image...');

            try {
                // Create a new image but don't display it yet
                originalImage = new Image();
                originalImage.src = URL.createObjectURL(file);

                // Wait for image to load
                await new Promise(r => originalImage.onload = r);
                drawImageToCanvas(originalCanvas, originalImage);

                // Enable click handling if model is ready
                if (!modelLoading) {
                    originalCanvas.style.cursor = 'crosshair';
                    updateStatus('Click anywhere on the image to set focus point.');
                }

                // Wait for model if still loading
                if (modelLoading) {
                    while (modelLoading) {
                        await new Promise(r => setTimeout(r, 100));
                    }
                }

                // Get depth map
                updateStatus('Estimating depth...');
                const result = await depthEstimator(originalImage.src);

                // Convert depth map to our format
                depthData = {
                    width: result.depth.width,
                    height: result.depth.height,
                    values: new Float32Array(result.depth.data).map(v => v / 255)
                };

                updateStatus('Ready! Click anywhere to set focus point.');
            } catch (error) {
                console.error('Error:', error);
                alert('Failed to process image. Please try again.');
                updateStatus('Error processing image');
            } finally {
                loadingOverlay.style.display = 'none';
            }
        });
    </script>
</body>

</html>